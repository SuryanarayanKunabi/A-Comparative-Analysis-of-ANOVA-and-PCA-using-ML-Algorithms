# -*- coding: utf-8 -*-
"""A Comparative Analysis of ANOVA and PCA for Modelling Credit Card Fraud Detection using Machine Learning Algorithms.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TP2VSu3GhHPC3v_vvC8dAXLXt8SobSjK

# A Comparative Analysis of ANOVA and PCA for Modelling Credit Card Fraud Detection using Machine Learning Algorithms

# Data Manipulation

Importing libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
#imported different libraries where we will be working with.

pd.set_option("display.max_rows", 100, "display.max_columns", 100)

"""Importing dataset"""

df=pd.read_csv('creditcard.csv')

"""Dataset View"""

df.head()

"""Dataset Information"""

df.info()

"""# Summary Statistics

Brief Information of different descriptive statistics-

*Measures of Frequency :- Count, Percent, Frequency.
*Measures of Central Tendency :- Mean, Median, and Mode.
*Measures of Dispersion or Variation:- Range(min,max),Variance, Standard Deviation.
*Measures of Position :- Percentile Ranks, Quartile Ranks.
"""

df.describe().style.background_gradient()

"""Checking for unique values in all attribute"""

df.nunique().sort_values(ascending=True)

df.Class.unique()

"""Checking for missing values in each column"""

df.isnull().sum()

"""percentage of missing values in each column"""

pd.options.display.float_format = '{:,.2f} %'.format
print((df.isnull().sum()/len(df))*100)
pd.options.display.float_format = '{:,.2f}'.format

pd.options.display.float_format = '{:,.2f} %'.format
print((df.isnull().sum()/len(df))*100)
pd.options.display.float_format = '{:,.2f}'.format

"""# Data Visualization

Missing Value Plot
"""

import missingno as msno

msno.matrix(df,labels=[df.columns],figsize=(30,16),fontsize=12)

"""Checking the data distribution of each Continuous variable"""

plt.figure(figsize=(18, 18))
for i, col in enumerate(df.select_dtypes(include=['float64']).columns):
    plt.rcParams['axes.facecolor'] = 'black'
    ax = plt.subplot(6,5, i+1)
    sns.histplot(data=df, x=col, ax=ax,color='red',kde=True)
plt.suptitle('Data distribution of continuous variables')
plt.tight_layout()

#This function will replace the outliers with the median from the dataset
def outlier_treating(data,var):
    df=data.copy()#creating a copy of the data
    def outlier_detector(data):#detecting the outliers
        outliers=[]
        q1=np.percentile(data,25)
        q3=np.percentile(data,75)
        IQR=q3-q1
        lb=q1-(IQR*1.5)
        ub=q3+(IQR*1.5)
        for i,j in enumerate(data):
            if(j<lb or j>ub):
                outliers.append(i)
        return outliers
    for i in var:
        out_var=outlier_detector(df[i])#calling outlier_detector function
        df.loc[out_var,i]=np.median(df[i])#replacing the outliers to the median
    return df

#selecting variables that have outliers
var=list(df.select_dtypes(include=['float64']).columns)

"""Data distribution after treating outliers"""

df=outlier_treating(df,var)

plt.figure(figsize=(18, 18))
for i, col in enumerate(df.select_dtypes(include=['float64']).columns):
    plt.rcParams['axes.facecolor'] = 'black'
    ax = plt.subplot(6,5, i+1)
    sns.histplot(data=df, x=col, ax=ax,color='red',kde=True)
plt.suptitle('Data distribution of continuous variables')
plt.tight_layout()

"""Box Plot"""

plt.figure(figsize=(18, 18))
for i, col in enumerate(df.select_dtypes(include=['float64']).columns):
    plt.rcParams['axes.facecolor'] = 'black'
    ax = plt.subplot(6,5, i+1)
    sns.boxplot(data=df, x=col, ax=ax,color='blue')
plt.suptitle('Box Plot of continuous variables')
plt.tight_layout()

"""# Heatmap"""

plt.figure(figsize=(18,18))
sns.heatmap(df.select_dtypes(include=['float']).corr(),annot=True,center = 0)
plt.show()

"""Bar Plot"""



plt.figure(figsize=(18, 18))
for i, col in enumerate(df.select_dtypes(include=['float64']).columns):
    plt.rcParams['axes.facecolor'] = 'black'
    ax = plt.subplot(6,5, i+1)
    sns.barplot(data=df,x='Class', y=col, ax=ax,edgecolor="black",palette='viridis_r')
plt.suptitle('Data distribution of continuous variables')
plt.tight_layout()

"""Analysing the target Variable

Quality

Pie Chart shows that the target class is Unbalanced
"""

target_var=pd.crosstab(index=df['Class'],columns='% observations')
plt.pie(target_var['% observations'],labels=target_var['% observations'].index,autopct='%.0f%%')
plt.title('Class')
plt.show()

"""Count plot shows that the target class is imbalanced"""

sns.barplot(x=target_var.index,y=target_var['% observations'])
plt.title('Class')
plt.show()

sns.scatterplot(x=df.V21,y=df.V22,hue=df.Class)
plt.show()

# First, import pandas.
import pandas as pd

# Then, read the creditcard dataset.
creditcard_data = pd.read_csv('creditcard.csv')

# Extract the Amount and Class columns.
amount_column = creditcard_data['Amount']
class_column = creditcard_data['Class']

# Count the number of entries in each column.
amount_count = len(amount_column)
class_count = len(class_column)

# Count the number of matching entries in each column.
amount_correct = 0
class_correct = 0

for i in range(amount_count):
  if amount_column[i] == amount_column[i]:
    amount_correct += 1

for i in range(class_count):
  if class_column[i] == class_column[i]:
    class_correct += 1

# Calculate the accuracy for each column.
amount_accuracy = amount_correct / amount_count
class_accuracy = class_correct / class_count

# Print the accuracy for each column.
print("Accuracy for Amount column:", amount_accuracy)
print("Accuracy for Class column:", class_accuracy)


# First, import matplotlib.
import matplotlib.pyplot as plt

# Define the data for the bars.
x = ['Amount', 'Class']
y = [amount_accuracy, class_accuracy]

# Create the bar plot.
plt.bar(x, y)

# Add a title and axis labels.
plt.title('Accuracy of Amount and Class Columns')
plt.xlabel('Column')
plt.ylabel('Accuracy')

# Show the plot.
plt.show()

# First, import pandas.
import pandas as pd

# Then, read the creditcard dataset.
creditcard_data = pd.read_csv('creditcard.csv')

# Extract the Amount and Class columns.
amount_column = creditcard_data['Amount']
class_column = creditcard_data['Class']

# Initialize a list to store the names of fields with fraud in Amount.
fraudulent_fields = []

# Get all column names except for the 'Time' and 'Class' columns.
column_names = creditcard_data.columns[1:-1]

# Loop through each column and check for frauds in the Amount field.
for column in column_names:
  # Extract the current column data.
  column_data = creditcard_data[column]

  # Loop through each entry in the current column.
  for i in range(len(column_data)):
    # Check if the corresponding entry in the Amount column is fraudulent.
    if class_column[i] == 1:
      # Add the current field name to the list of fraudulent fields.
      fraudulent_fields.append(column)

# Print the list of fraudulent fields.
print("Fields with fraud in Amount field:", fraudulent_fields)





# First, import matplotlib.
import matplotlib.pyplot as plt

# Define the data for the bar plot.
x = fraudulent_fields
y = [fraudulent_fields.count(field) for field in fraudulent_fields]

# Create the bar plot.
plt.bar(x, y)

# Add a title and axis labels.
plt.title('Fraudulent Fields in Amount Field')
plt.xlabel('Field Name')
plt.ylabel('Number of Frauds')

# Show the plot.
plt.show()

# First, import pandas.
import pandas as pd

# Then, read the creditcard dataset.
creditcard_data = pd.read_csv('creditcard.csv')

# Get all column names except for the 'Time' and 'Class' columns.
column_names = creditcard_data.columns[1:-1]

# Initialize a dictionary to store the number of frauds in each column.
column_frauds = {}

# Loop through each column and count the number of frauds.
for column in column_names:
  # Extract the current column data.
  column_data = creditcard_data[column]

  # Count the number of fraudulent entries in the current column.
  fraud_count = 0
  for value in column_data:
    if value == 1:
      fraud_count += 1

  # Store the number of frauds in the dictionary.
  column_frauds[column] = fraud_count

# Print the number of frauds in each column.
for column, fraud_count in column_frauds.items():
  print("Number of frauds in", column, "column:", fraud_count)

X=df.iloc[:,0:-1]
y=df.iloc[:,-1]



"""# Feature Selection"""

y = y.dropna()

from sklearn.impute import SimpleImputer



from imblearn.over_sampling import SMOTE



# Remove rows with NaN values in y
y = y.dropna()

X = X.dropna()

from sklearn.impute import SimpleImputer



from imblearn.over_sampling import SMOTE



# Remove rows with NaN values in y
X = X.dropna()

"""# Chi-Square Test"""

import pandas as pd
from sklearn.feature_selection import chi2

# Load the creditcard dataset
df = pd.read_csv("creditcard.csv")

# Remove NaN values from X
X = df.drop("Class", axis=1).dropna()

# Extract target variable
y = df["Class"]


import pandas as pd
from sklearn.feature_selection import chi2

# Load the creditcard dataset
df = pd.read_csv("creditcard.csv")

# Remove NaN values from X
X = df.drop("Class", axis=1).dropna()

# Replace negative values with 0
X[X < 0] = 0

# Extract target variable
y = df["Class"]

# Perform chi-square test
chi_scores, p_values = chi2(X, y)

# Select features with p-value less than 0.05
selected_features = X.columns[p_values < 0.05]

# Create a new DataFrame with selected features
X_selected = X[selected_features]

# Print the number of selected features
print(f"Number of selected features: {len(selected_features)}")

# Print the selected features
print(f"Selected features: {selected_features.tolist()}")



# Perform chi-square test
chi_scores, p_values = chi2(X, y)

# Select features with p-value less than 0.05
selected_features = X.columns[p_values < 0.05]

# Create a new DataFrame with selected features
X_selected = X[selected_features]

# Print the number of selected features
print(f"Number of selected features: {len(selected_features)}")

# Print the selected features
print(f"Selected features: {selected_features.tolist()}")

"""Post-hoc Tukey HSD"""

import pandas as pd
import numpy as np
import scipy.stats as stats
import statsmodels.stats.multicomp as mc

# Load the data
df = pd.read_csv("creditcard.csv")

# Perform one-way ANOVA on each feature
pvalues = {}
for col in df.columns:
  if col == "Class":
    continue
  groups = df.groupby("Class")[col].apply(list)
  pvalues[col] = stats.f_oneway(*groups)[1]

# Select features with p-value less than 0.05
selected_features = [col for col, pval in pvalues.items() if pval < 0.05]

# Perform Tukey HSD test on selected features
for col in selected_features:
  groups = df.groupby("Class")[col].apply(list)
  mc_results = mc.MultiComparison(np.concatenate(groups), np.repeat(df["Class"].values, [len(group) for group in groups]).ravel().reshape(-1, 1))
  tukey_results = mc_results.tukeyhsd()
  print(tukey_results.summary())

"""# ANOVA"""

from sklearn.feature_selection import f_classif#ANOVA

# Find the indices of rows with missing values in X
nan_indices = np.isnan(X).any(axis=1)

# Remove the rows with missing values from X
X = X[~nan_indices]

missing_values_in_y = y.isna().sum()

if missing_values_in_y > 0:
    print(f"There are {missing_values_in_y} missing values in the target variable 'y'.")
    # Handle missing values (e.g., drop rows with missing values)
    from sklearn.impute import SimpleImputer

    y = y.dropna()
X = X.loc[y.index]




fs = f_classif(X, y)

fs =f_classif(X,y)

selected_var=[]
print('if p-value<0.05 : Reject the null hypothesis \nif p-value>0.05 :Fail to relect the null hypothesis.\n')
for i,j in enumerate(X.columns):
    print(f'Null hypothesis: There is no significant difference between the mean {j} among different groups of Class.')
    print(f'Alternate Hypothesis: There is a significant difference between the mean {j} among different groups of Class.')
    if fs[1][i]<0.05:#p-values<0.05
        print(f'{j} : Reject the null hypothesis.\n')
    else:
        print(f'{j} : Fail to reject the null hypothesis.\n')
        selected_var.append(j)

# Find the indices of rows with missing values in X
nan_indices = np.isnan(X).any(axis=1)

# Remove the rows with missing values from X
X = X[~nan_indices]

from sklearn.impute import SimpleImputer
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Create an imputer object
imputer = SimpleImputer(strategy="mean")

# Impute missing values in X
X_imputed = imputer.fit_transform(X)

# Perform PCA on the imputed data
X_pca = pca.fit_transform(X_imputed)



# Find the indices of rows with missing values in X
nan_indices = np.isnan(X).any(axis=1)

# Remove the rows with missing values from X
X_without_nan = X[~nan_indices]

# Perform PCA on the data without missing values
X_pca = pca.fit_transform(X_without_nan)

import pandas as pd
from sklearn.decomposition import PCA

# Load the creditcard dataset
data = pd.read_csv("creditcard.csv")

# Separate features (X) and target variable (y)
X = data.drop('Class', axis=1)
y = data['Class']

# Remove rows with missing values from X
X_without_nan = X.dropna()

# Standardize the features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_without_nan)

# Perform PCA
pca = PCA()
X_pca = pca.fit_transform(X_scaled)

# Print the explained variance ratio
print("Explained Variance Ratio:", pca.explained_variance_ratio_)

# Determine the number of components to retain
# For example, if you want to retain 95% of the variance
cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)
num_components = np.argmax(cumulative_variance_ratio >= 0.95) + 1

# Retain only the selected number of components
X_pca_selected = X_pca[:, :num_components]

# Now, you can use X_pca_selected for further analysis or modeling


import matplotlib.pyplot as plt

# Plot the explained variance ratio for each principal component
plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, marker='o')
plt.xlabel('Number of Components')
plt.ylabel('Explained Variance Ratio')
plt.title('Scree Plot')
plt.show()

# Determine the number of components to retain based on the scree plot or cumulative explained variance
# For example, if you want to retain 95% of the variance
cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)
num_components = np.argmax(cumulative_variance_ratio >= 0.95) + 1

# Print the number of components to retain
print(f"Number of components to retain: {num_components}")

"""# SMOTE(Synthetic Minority Oversampling Technique)"""

X=X[selected_var]

from imblearn.over_sampling import SMOTE

sm = SMOTE(sampling_strategy='auto', random_state=42)

y = y.dropna()

from sklearn.impute import SimpleImputer



from imblearn.over_sampling import SMOTE



# Remove rows with NaN values in y
y = y.dropna()

X = X.dropna()

from sklearn.impute import SimpleImputer



from imblearn.over_sampling import SMOTE



# Remove rows with NaN values in y
X = X.dropna()

"""Count plot after applying SMOTE"""

sns.countplot(y)
plt.show()

"""# Splitting our dataset into train and test set"""

from sklearn.model_selection import train_test_split

y = y.dropna()

from sklearn.impute import SimpleImputer



from imblearn.over_sampling import SMOTE



# Remove rows with NaN values in y
y = y.dropna()

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,stratify=y,random_state=0)

"""# Feature Scaling"""

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.transform(X_test)

# Import necessary libraries
import pandas as pd

# Load the dataset
df = pd.read_csv('creditcard.csv')

# Separate the target variable from the features
target = df['Class']
features = df.drop('Class', axis=1)

# Train an isolation forest model
from sklearn.ensemble import IsolationForest
model = IsolationForest(contamination='auto')
model.fit(features)

# Predict fraud
fraud = model.predict(features)

# Count the number of fraudulent transactions
fraud_count = len(fraud[fraud == -1])

# Print the overall fraud percentage
overall_fraud_percentage = (fraud_count / len(fraud)) * 100
print(f"Overall fraud percentage: {overall_fraud_percentage:.2f}%")




import matplotlib.pyplot as plt

# Create a bar chart
plt.bar('Fraud', fraud_count)
plt.xlabel('Type')
plt.ylabel('Count')
plt.title('Overall Fraud')
plt.show()

# Create a pie chart
labels = ['Genuine', 'Fraud']
sizes = [100 - overall_fraud_percentage, overall_fraud_percentage]
fig1, ax1 = plt.subplots()
ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)
ax1.axis('equal')
plt.title('Overall Fraud')
plt.show()

"""# Modeling"""

#importing different classification models
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, accuracy_score,f1_score
from sklearn.metrics import classification_report
from xgboost import XGBClassifier
#creating dictionary for storing different models accuracy
model_comparison={}

classifier=DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
classifier.fit(X_train,y_train)
y_pred=classifier.predict(X_test)
print("PCA Comparision\n")
print(f"Model Accuracy : {accuracy_score(y_pred,y_test)*100:.2f}%")
print(f"Model F1-Score : {f1_score(y_pred,y_test,average='weighted')*100:.2f}%")
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5)
print("Cross Val Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Cross Val Standard Deviation: {:.2f} %".format(accuracies.std()*100))
print(classification_report(y_pred,y_test,zero_division=1))
model_comparison['Decision Tree']=[accuracy_score(y_pred,y_test),f1_score(y_pred,y_test,average='weighted'),(accuracies.mean()),(accuracies.std())]

classifier=RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(X_train,y_train)
y_pred=classifier.predict(X_test)
print("ANOVA Comparision\n")
print(f"Model Accuracy : {accuracy_score(y_pred,y_test)*100:.2f}%")
print(f"Model F1-Score : {f1_score(y_pred,y_test,average='weighted')*100:.2f}%")
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5)
print("Cross Val Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Cross Val Standard Deviation: {:.2f} %".format(accuracies.std()*100))
print(classification_report(y_pred,y_test,zero_division=1))
model_comparison['Random Forest']=[accuracy_score(y_pred,y_test),f1_score(y_pred,y_test,average='weighted'),(accuracies.mean()),(accuracies.std())]

Model_com_df=pd.DataFrame(model_comparison).T
Model_com_df.columns=['Model Accuracy','Model F1-Score','CV Accuracy','CV std']
Model_com_df=Model_com_df.sort_values(by='Model F1-Score',ascending=False)
Model_com_df.style.format("{:.2%}").background_gradient(cmap='Blues')

Model_com_df.style.highlight_max().set_caption("Maximum Score in each Column").format("{:.2%}")

Model_com_df.style.highlight_min().set_caption("Minimum Score in each Column").format("{:.2%}")



